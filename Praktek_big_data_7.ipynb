{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPNNbVgRoKzJPVCWISpQu8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romirahmanw112/BigData2/blob/main/Praktek_big_data_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java 8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Kafka\n",
        "!wget -q https://archive.apache.org/dist/kafka/3.6.0/kafka_2.12-3.6.0.tgz\n",
        "!tar -xzf kafka_2.12-3.6.0.tgz\n",
        "\n",
        "# Download Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "\n",
        "# Install Python libraries\n",
        "!pip install -q findspark kafka-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaiFxEshaV7f",
        "outputId": "80ee8f2a-0eb3-434c-d7db-b570a776bd17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/326.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.3/326.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "os.environ[\"KAFKA_HOME\"] = \"/content/kafka_2.12-3.6.0\"\n",
        "\n",
        "findspark.init()\n"
      ],
      "metadata": {
        "id": "tScglJ8Ba0p_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Jalankan Zookeeper\n",
        "!nohup $KAFKA_HOME/bin/zookeeper-server-start.sh \\\n",
        "$KAFKA_HOME/config/zookeeper.properties > /dev/null 2>&1 &\n",
        "\n",
        "import time\n",
        "print(\"Menunggu Zookeeper start (10 detik)...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Jalankan Kafka Broker\n",
        "!nohup $KAFKA_HOME/bin/kafka-server-start.sh \\\n",
        "$KAFKA_HOME/config/server.properties > /dev/null 2>&1 &\n",
        "\n",
        "print(\"Menunggu Kafka Broker start (10 detik)...\")\n",
        "time.sleep(10)\n",
        "\n",
        "print(\"Kafka Server SIAP!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBX4BFA8a3cH",
        "outputId": "c9ff15f6-f7fa-4097-a933-15f267fd688f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menunggu Zookeeper start (10 detik)...\n",
            "Menunggu Kafka Broker start (10 detik)...\n",
            "Kafka Server SIAP!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!$KAFKA_HOME/bin/kafka-topics.sh \\\n",
        "--create \\\n",
        "--topic transaksi-toko \\\n",
        "--bootstrap-server localhost:9092 \\\n",
        "--replication-factor 1 \\\n",
        "--partitions 1\n",
        "\n",
        "print(\"Topik transaksi-toko berhasil dibuat\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJtmv0-dbAAw",
        "outputId": "bb5b3f7c-c005-4125-ce9c-2013a6fed1d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic transaksi-toko.\n",
            "Topik transaksi-toko berhasil dibuat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kafka import KafkaProducer\n",
        "import json, time, random\n",
        "from datetime import datetime\n",
        "\n",
        "def json_serializer(data):\n",
        "    return json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    value_serializer=json_serializer\n",
        ")\n",
        "\n",
        "products = [\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\", \"HDMI Cable\"]\n",
        "\n",
        "def send_stream_data(topic_name, num_messages=50):\n",
        "    for i in range(num_messages):\n",
        "        data = {\n",
        "            \"transaction_id\": i,\n",
        "            \"product\": random.choice(products),\n",
        "            \"price\": random.randint(100000, 5000000),\n",
        "            \"quantity\": random.randint(1, 5),\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        }\n",
        "        producer.send(topic_name, data)\n",
        "        time.sleep(0.1)\n",
        "\n",
        "    print(\"Data berhasil dikirim ke Kafka\")\n"
      ],
      "metadata": {
        "id": "w_M2kZapbEgG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import from_json, col, sum as _sum\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"KafkaSparkStreaming\") \\\n",
        "    .config(\n",
        "        \"spark.jars.packages\",\n",
        "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\"\n",
        "    ) \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "print(\"Spark Session aktif\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz2CfleRbHgP",
        "outputId": "24f2cc5e-6a70-49b9-9352-50d0c767cd70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Session aktif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"transaction_id\", IntegerType()),\n",
        "    StructField(\"product\", StringType()),\n",
        "    StructField(\"price\", IntegerType()),\n",
        "    StructField(\"quantity\", IntegerType()),\n",
        "    StructField(\"timestamp\", StringType())\n",
        "])\n",
        "\n",
        "df_raw = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "    .option(\"subscribe\", \"transaksi-toko\") \\\n",
        "    .option(\"startingOffsets\", \"earliest\") \\\n",
        "    .load()\n",
        "\n",
        "df_parsed = df_raw.select(\n",
        "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")\n",
        ").select(\"data.*\")\n",
        "\n",
        "df_parsed.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXsdozTObUY-",
        "outputId": "797fb334-8021-4934-da19-1d6c6e927d41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- transaction_id: integer (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- price: integer (nullable = true)\n",
            " |-- quantity: integer (nullable = true)\n",
            " |-- timestamp: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_revenue = df_parsed.withColumn(\n",
        "    \"revenue\",\n",
        "    col(\"price\") * col(\"quantity\")\n",
        ")\n",
        "\n",
        "df_analysis = df_with_revenue.groupBy(\"product\") \\\n",
        "    .agg(_sum(\"revenue\").alias(\"total_sales\")) \\\n",
        "    .orderBy(\"total_sales\", ascending=False)\n"
      ],
      "metadata": {
        "id": "SpELU__BbZxO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = df_analysis.writeStream \\\n",
        "    .outputMode(\"complete\") \\\n",
        "    .format(\"memory\") \\\n",
        "    .queryName(\"sales_table\") \\\n",
        "    .start()\n",
        "\n",
        "print(\"Streaming berjalan di background\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVEdyfMGbcZv",
        "outputId": "4e330fd8-bcc6-47a8-adf6-03556d92387a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming berjalan di background\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "send_stream_data(\"transaksi-toko\", num_messages=50)\n",
        "\n",
        "time.sleep(5)\n",
        "\n",
        "result = spark.sql(\"SELECT * FROM sales_table\")\n",
        "result.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPvQHxBfbg-H",
        "outputId": "fb68bea9-c1de-40a7-eec6-a82bb146e01d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data berhasil dikirim ke Kafka\n",
            "+-------+-----------+\n",
            "|product|total_sales|\n",
            "+-------+-----------+\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.stop()\n",
        "print(\"Streaming dihentikan\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drQkVLv7bm72",
        "outputId": "7399149c-c02c-4fe4-8c0f-62866b928ff4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming dihentikan\n"
          ]
        }
      ]
    }
  ]
}